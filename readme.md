

# End-to-End Geometric Deep Learning Framework for Structure-Based Drug Discovery

## Project Overview

This project represents a comprehensive Deep Learning framework encompassing the entire lifecycle of **AI-Driven Drug Discovery**. It implements state-of-the-art methodologies in **Geometric Deep Learning** and **Generative Models** to perform Molecular Property Prediction, 3D Conformation Analysis, and De Novo Drug Design.

Beyond simple model implementation, this framework prioritizes engineering rigorâ€”incorporating **Hyperparameter Tuning, Early Stopping, and Modular Architecture**â€”to ensure code reusability and model robustness in practical applications.

### Key Features

* **Molecular Property Prediction:** Implemented GCN baselines and GAT (Graph Attention Networks) with a context-aware inference pipeline for Lipophilicity (LogP) prediction.
* **3D Structure Analysis:** 3D Conformation-aware learning using RDKit for conformer generation and **SchNet** for energy modeling.
* **Generative Chemistry:** Latent space extraction via **VGAE** and structural generation using **Diffusion Models**.
* **Proteinâ€“Ligand Interaction:** Radius-graph contact analysis and PDB complex preprocessing with PyMOL visualization integration.

## Relevance to Protein Design

Protein and antibody design are fundamentally constrained by 3D geometry and structural validation loops. This project demonstrates core competencies required for structural biology AI:

* **Data Foundations:** Seamless handling of sequence-to-structure data (SMILES â†” 3D, PDB â†” 3D Graphs).
* **Geometric Deep Learning:** Proficiency with **PyTorch Geometric** and interaction-based architectures (SchNet/GAT).
* **Structural Analysis:** Implementation of radius-graph based contact analysis for molecular interactions.
* **Reproducibility:** Rigorous training protocols including seed fixing, early stopping, and checkpoint management.

---

## Model Architectures & Methodologies

The framework consists of four core modules tailored to specific research objectives:

### 1. Molecular Property Prediction (Graph Neural Networks)

A regression framework designed to precisely predict drug lipophilicity (LogP).

* **GCN (Graph Convolutional Network):** Serves as the baseline model for molecular graph learning.
* **GAT (Graph Attention Network):** Incorporates self-attention mechanisms to learn interaction weights between functional groups, significantly outperforming the baseline.

### 2. 3D Structure Analysis (Geometric Deep Learning)

Utilizes 3D atomic coordinates in addition to 2D topological information.

* **SchNet:** Applies continuous-filter convolutions to model inter-atomic distances and interaction energies effectively.

### 3. Generative Chemistry (De Novo Design)

Generative AI models for discovering novel drug candidates.

* **VGAE (Variational Graph Autoencoder):** Learns the latent space of molecular graphs for structure generation.
* **Diffusion Model (Score-based Generative Modeling):** Generates stable 3D molecular conformations via a denoising process.

### 4. Protein-Ligand Interaction

* **Binding Simulation:** Analyzes binding affinity between target proteins (PDB) and ligands using radius-graph based interaction modeling.

---

## Performance Benchmarks

Extensive comparative experiments were conducted using the `MoleculeNet (Lipo)` dataset to evaluate various architectures and validation strategies. The **GAT (64-channel)** model demonstrated the best performance and was selected as the backbone for the final pipeline.

### 1. Comparative Experiment Results (Lower MAE is Better)

| Model Architecture | Variant | Metric | Score (MAE) | Finding |
| --- | --- | --- | --- | --- |
| **GAT (Winner)** ğŸ† | **64ch (Pure)** | **Real MAE** | **0.5343** | **Optimal Capacity & Generalization** |
| GAT | 64ch (3-Split) | Val MAE | 0.5537 | Rigorous Validation (Train/Val/Test) |
| GAT | 128ch (High-Cap) | Real MAE | 0.5619 | Slight Overfitting observed |
| GCN | 64ch (Baseline) | Real MAE | 0.5868 | Lower expressivity than GAT |
| GCN | 3-Split | Val MAE | 0.6374 | Baseline Validation |

> **Key Insights:**
> * **Model Capacity:** The 64-channel model outperformed the 128-channel variant, suggesting that excessive capacity relative to the dataset size (4.2k samples) leads to overfitting.
> * **Architecture:** GAT (utilizing Self-Attention) achieved approximately 10% lower error rates compared to the GCN baseline, validating the importance of attention mechanisms in molecular representation.
> 
> 

### 2. Final Inference Strategy: Hybrid System

To overcome the limitations of single models, I constructed an intelligent inference system based on **Data Retrieval and Similarity Scoring**.

> **"Hybrid Inference System: Combines High-Precision GAT with Robust Uncertainty Management using Data Retrieval."**

* **Logic:** The system dynamically selects the optimal model by calculating the Tanimoto Similarity between the input molecule and the training dataset.
* **High Similarity (> 0.5): Deploy Model A (Pure GAT)**
* The input is within the "Known Domain." The system prioritizes **Precision** by using the expert model.


* **Low Similarity (â‰¤ 0.5): Deploy Model B (Dropout GAT)**
* The input is "Out-of-Distribution (OOD)." The system prioritizes **Robustness** and safety by using the regularized model to prevent hallucination or extreme errors.


* **Threshold Optimization (Calibration)**
 While a default threshold of 0.5 is used for demonstration due to the dataset size, the optimal cutoff is scientifically derived using 6_0_calibrate_gate_threshold.py. This script performs a Grid Search on the validation set to find the exact similarity score that minimizes the overall RMSE. This ensures the switching logic in 6_1_inference_logp_real_world_prediction_ensemble.py is based on data-driven evidence rather than intuition.



---

## Repository Structure

```text
Drug-Discovery-AI/
â”œâ”€â”€ 01_Property_Prediction/   # GNN (GCN, GAT) Training & Inference
â”œâ”€â”€ 02_3D_Structure/          # SchNet Training
â”œâ”€â”€ 03_Generative_AI/         # Generative Models (VGAE, Diffusion)
â”œâ”€â”€ 04_Molecular_Interaction/ # Protein-Ligand Binding Simulation
â”œâ”€â”€ docs/                     # Experiment Reports & Documentation
â””â”€â”€ data/                     # Dataset Storage

```

## Usage & Reproduction

This project requires `Python 3.8+` and `PyTorch Geometric`.

### Installation

For detailed setup, please refer to **`install_guide.md`**.

```bash
pip install -r requirements.txt

```

### 1. Property Prediction

Training and Inference using Graph Attention Networks (GAT):

```bash
# Training
python 01_Property_Prediction/train_gat.py

# Inference (Real-world Data / Hybrid System)
python 01_Property_Prediction/6_8_inference_final_complete.py

```

### 2. 3D Molecular Analysis

Training SchNet for 3D structure and energy prediction:

```bash
python 02_3D_Structure/train_schnet.py

```

### 3. Generative Models

Generating 3D molecular structures using Diffusion Models:

```bash
# Training
python 03_Generative_AI/train_diffusion.py

# Generation (Inference)
python 03_Generative_AI/inference_diffusion.py

```

### 4. Interaction Simulation

Simulating binding affinity for specific targets (e.g., Gleevec):

```bash
python 04_Molecular_Interaction/binding_gleevec.py

```

---

## 5. Protein Design Demo (ProteinMPNN â†’ ColabFold â†’ Scoring)

A demonstration pipeline tailored for protein design tasks. It covers the **Design â†’ Predict â†’ Validate** loop:

1. **Design:** Sequence generation using ProteinMPNN.
2. **Predict:** Structure prediction using ColabFold (AlphaFold2).
3. **Validate:** Candidate ranking via pLDDT and RMSD metrics.

* See details: `05_protein_design_demo/README.md`

## Outputs

* `final_prediction.png`: Visualization of Real vs. Predicted LogP values.
* `binding_pymol_final.png`: PyMOL visualization of Protein-Ligand interactions.

## License

Distributed under the MIT License. See `LICENSE` for more information.








---

# êµ¬ì¡° ê¸°ë°˜ ì‹ ì•½ ê°œë°œì„ ìœ„í•œ ì—”ë“œíˆ¬ì—”ë“œ ê¸°í•˜í•™ì  ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬

**(End-to-End Geometric Deep Learning Framework for Structure-Based Drug Discovery)**

## 1. í”„ë¡œì íŠ¸ ê°œìš” (Project Overview)

ë³¸ í”„ë¡œì íŠ¸ëŠ” **AI ê¸°ë°˜ ì‹ ì•½ ê°œë°œ(AI-Driven Drug Discovery)**ì˜ ì „ ì£¼ê¸°ë¥¼ í¬ê´„í•˜ëŠ” ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë¶„ì ë¬¼ì„± ì˜ˆì¸¡(Property Prediction), 3D êµ¬ì¡° ë¶„ì„(Conformation Analysis), ê·¸ë¦¬ê³  ì‹ ê·œ í›„ë³´ ë¬¼ì§ˆ ìƒì„±(De Novo Design)ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ **Geometric Deep Learning**ê³¼ **Generative Models**ì˜ ìµœì‹  ë°©ë²•ë¡ ì„ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤.

ë‹¨ìˆœí•œ ëª¨ë¸ êµ¬í˜„ì„ ë„˜ì–´, ì‹¤ë¬´ ì ìš©ì„ ê³ ë ¤í•œ **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”(Hyperparameter Tuning), ì¡°ê¸° ì¢…ë£Œ(Early Stopping), ëª¨ë“ˆí™”ëœ ì•„í‚¤í…ì²˜(Modular Architecture)**ë¥¼ ì ìš©í•˜ì—¬ ì½”ë“œì˜ ì¬ì‚¬ìš©ì„±ê³¼ ëª¨ë¸ì˜ ê°•ê±´ì„±(Robustness)ì„ í™•ë³´í•˜ì˜€ìŠµë‹ˆë‹¤.

### í•µì‹¬ êµ¬í˜„ ì‚¬í•­

* **ë¬¼ì„± ì˜ˆì¸¡:** GCN ë² ì´ìŠ¤ë¼ì¸ êµ¬ì¶• ë° Self-Attention ê¸°ë°˜ì˜ GAT ëª¨ë¸ ìµœì í™” (Context-Aware Inference íŒŒì´í”„ë¼ì¸ ì ìš©).
* **3D êµ¬ì¡° ë¶„ì„:** RDKitì„ í™œìš©í•œ Conformer ìƒì„± ë° **SchNet**ì„ ì´ìš©í•œ 3D ì—ë„ˆì§€ ëª¨ë¸ë§.
* **ìƒì„±í˜• ëª¨ë¸ë§:** **VGAE**ë¥¼ í†µí•œ ì ì¬ ê³µê°„(Latent Space) ì¶”ì¶œ ë° **Diffusion Model**ì„ í™œìš©í•œ 3D êµ¬ì¡° ìƒì„± ë°ëª¨.
* **ë‹¨ë°±ì§ˆ-ë¦¬ê°„ë“œ ìƒí˜¸ì‘ìš©:** Radius Graph ê¸°ë°˜ì˜ ì ‘ì´‰(Contact) ë¶„ì„ ë° PDB ë³µí•©ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸.

---

## 2. ë‹¨ë°±ì§ˆ ë””ìì¸ ì§ë¬´ì™€ì˜ ì—°ê´€ì„± (Relevance to Protein Design)

ë‹¨ë°±ì§ˆ ë° í•­ì²´ ë””ìì¸ ë¬¸ì œëŠ” 3ì°¨ì› ê¸°í•˜í•™ì  ì œì•½ ì¡°ê±´ê³¼ êµ¬ì¡°ì  ê²€ì¦ ë£¨í”„(Structural Validation Loop)ê°€ í•µì‹¬ì…ë‹ˆë‹¤. ë³¸ í”„ë¡œì íŠ¸ëŠ” êµ¬ì¡° ìƒë¬¼í•™ AI ì—”ì§€ë‹ˆì–´ì—ê²Œ í•„ìˆ˜ì ì¸ ë‹¤ìŒì˜ ì—­ëŸ‰ì„ ì…ì¦í•©ë‹ˆë‹¤.

* **ë°ì´í„° í•¸ë“¤ë§:** ì„œì—´-êµ¬ì¡° ë°ì´í„° ê°„ì˜ ë³€í™˜ ë° ì²˜ë¦¬ (SMILES â†” 3D, PDB â†” 3D Graph).
* **ê¸°í•˜í•™ì  ë”¥ëŸ¬ë‹:** **PyTorch Geometric** í™œìš© ëŠ¥ë ¥ ë° ìƒí˜¸ì‘ìš© ê¸°ë°˜ ì•„í‚¤í…ì²˜(SchNet, GAT) êµ¬í˜„ ê²½í—˜.
* **êµ¬ì¡° ë¶„ì„:** Radius Graphë¥¼ í™œìš©í•œ ë¶„ì ê°„ ìƒí˜¸ì‘ìš© ëª¨ë¸ë§ ë° ì‹œê°í™”.
* **ì—°êµ¬ ì¬í˜„ì„±:** Seed ê³ ì •, ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬, ì—„ê²©í•œ ê²€ì¦(Validation)ì„ í†µí•œ ì‹¤í—˜ì˜ ì¬í˜„ì„± í™•ë³´.

---

## 3. ëª¨ë¸ ì•„í‚¤í…ì²˜ ë° ë°©ë²•ë¡  (Model Architectures & Methodologies)

ë³¸ í”„ë ˆì„ì›Œí¬ëŠ” ì—°êµ¬ ëª©ì ì— ë”°ë¼ ì´ 4ê°œì˜ í•µì‹¬ ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

### 1) Molecular Property Prediction (Graph Neural Networks)

ì•½ë¬¼ì˜ ì§€ì§ˆ ì¹œí™”ë„(Lipophilicity, LogP)ë¥¼ ì •ë°€í•˜ê²Œ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ íšŒê·€(Regression) í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

* **GCN (Graph Convolutional Network):** ë¶„ì ê·¸ë˜í”„ í•™ìŠµì„ ìœ„í•œ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸.
* **GAT (Graph Attention Network):** Self-Attention ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ê¸°ëŠ¥ê¸°(Functional Group) ê°„ì˜ ìƒí˜¸ì‘ìš© ê°€ì¤‘ì¹˜ë¥¼ í•™ìŠµ, ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”í–ˆìŠµë‹ˆë‹¤.

### 2) 3D Structure Analysis (Geometric Deep Learning)

ë¶„ìì˜ 2D ìœ„ìƒ ì •ë³´ë¿ë§Œ ì•„ë‹ˆë¼, 3ì°¨ì› ê³µê°„ ì¢Œí‘œ(Atomic Coordinates)ë¥¼ í•™ìŠµì— í™œìš©í•©ë‹ˆë‹¤.

* **SchNet:** Continuous-filter Convolutionì„ ì ìš©í•˜ì—¬ ì›ì ê°„ ê±°ë¦¬ ì •ë³´ì™€ ìƒí˜¸ì‘ìš© ì—ë„ˆì§€ë¥¼ ëª¨ë¸ë§í•©ë‹ˆë‹¤.

### 3) Generative Chemistry (De Novo Design)

ì‹ ê·œ ì•½ë¬¼ í›„ë³´ ë¬¼ì§ˆ íƒìƒ‰ì„ ìœ„í•œ ìƒì„±í˜• AI ëª¨ë¸ì…ë‹ˆë‹¤.

* **VGAE (Variational Graph Autoencoder):** ë¶„ì ê·¸ë˜í”„ì˜ ì ì¬ ê³µê°„ì„ í•™ìŠµí•˜ì—¬ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
* **Diffusion Model (Score-based Generative Modeling):** ë…¸ì´ì¦ˆ ì œê±°(Denoising) ê³¼ì •ì„ í†µí•´ ì•ˆì •ì ì¸ 3D ë¶„ì êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

### 4) Protein-Ligand Interaction

* **Binding Simulation:** íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ(PDB)ê³¼ ë¦¬ê°„ë“œ ê°„ì˜ ê²°í•© ì¹œí™”ë„(Binding Affinity)ë¥¼ Radius Graph ê¸°ë°˜ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.

---

## 4. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ (Performance Benchmarks)

`MoleculeNet (Lipo)` ë°ì´í„°ì…‹ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ì™€ ê²€ì¦ ì „ëµì„ ë¹„êµ ì‹¤í—˜í•˜ì˜€ìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, **GAT (64ì±„ë„)** ëª¨ë¸ì´ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ì˜€ìŠµë‹ˆë‹¤.

### 1) ë¹„êµ ì‹¤í—˜ ê²°ê³¼ (MAE: ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)

| Model Architecture | Variant | Metric | Score (MAE) | Finding |
| --- | --- | --- | --- | --- |
| **GAT (Winner)** ğŸ† | **64ch (Pure)** | **Real MAE** | **0.5343** | **ìµœì  ìš©ëŸ‰(Optimal Capacity) ë° ì¼ë°˜í™” ì„±ëŠ¥ í™•ë³´** |
| GAT | 64ch (3-Split) | Val MAE | 0.5537 | ì—„ê²©í•œ ê²€ì¦ (Train/Val/Test ë¶„í• ) |
| GAT | 128ch (High-Cap) | Real MAE | 0.5619 | ëª¨ë¸ í¬ê¸° ì¦ê°€ë¡œ ì¸í•œ ì•½ê°„ì˜ ê³¼ì í•© ê´€ì°° |
| GCN | 64ch (Baseline) | Real MAE | 0.5868 | GAT ëŒ€ë¹„ í‘œí˜„ë ¥(Expressivity) ë¶€ì¡± |
| GCN | 3-Split | Val MAE | 0.6374 | ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ ê²°ê³¼ |

> **í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (Key Insights):**
> * **Model Capacity:** 128ì±„ë„ ëª¨ë¸ë³´ë‹¤ 64ì±„ë„ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë” ìš°ìˆ˜í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë°ì´í„°ì…‹ í¬ê¸°(4.2k) ëŒ€ë¹„ ëª¨ë¸ì´ ì§€ë‚˜ì¹˜ê²Œ í¬ë©´ ê³¼ì í•©(Overfitting)ì´ ë°œìƒí•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> * **Architecture:** Self-Attentionì„ ì‚¬ìš©í•˜ëŠ” GATê°€ GCNë³´ë‹¤ ì•½ 10% ë” ë‚®ì€ ì˜¤ì°¨ìœ¨ì„ ê¸°ë¡í•˜ì—¬, ë¶„ì í‘œí˜„ í•™ìŠµì—ì„œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ì¤‘ìš”ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
> 
> 

### 2) ìµœì¢… ì¶”ë¡  ì „ëµ: í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ (Hybrid Inference System)

ë‹¨ì¼ ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, **ë°ì´í„° ê²€ìƒ‰(Data Retrieval) ë° ìœ ì‚¬ë„(Similarity)**ì— ê¸°ë°˜í•œ ì§€ëŠ¥í˜• ì¶”ë¡  ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì˜€ìŠµë‹ˆë‹¤.

> **"Hybrid Inference System: Combines High-Precision GAT with Robust Uncertainty Management using Data Retrieval."**
> (ê³ ì •ë°€ GATì™€ ë°ì´í„° ê²€ìƒ‰ ê¸°ë°˜ ë¶ˆí™•ì‹¤ì„± ê´€ë¦¬ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ë¡  ì‹œìŠ¤í…œ)

* **ì‘ë™ ë¡œì§:** ì…ë ¥ ë¶„ìì™€ í•™ìŠµ ë°ì´í„° ê°„ì˜ íƒ€ë‹ˆëª¨í†  ìœ ì‚¬ë„(Tanimoto Similarity)ë¥¼ ê³„ì‚°í•˜ì—¬ ëª¨ë¸ì„ ë™ì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
* **High Similarity (> 0.5): Model A (Pure GAT) ì‚¬ìš©**
* ì…ë ¥ì´ "í•™ìŠµëœ ë„ë©”ì¸(Known Domain)"ì— ì†í•¨. **ì •ë°€ë„(Precision)**ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í•˜ì—¬ ì „ë¬¸ê°€ ëª¨ë¸ì„ ì‚¬ìš©.


* **Low Similarity (â‰¤ 0.5): Model B (Dropout GAT) ì‚¬ìš©**
* ì…ë ¥ì´ "ë¶„í¬ ì™¸ ë°ì´í„°(OOD)"ì— ì†í•¨. **ê°•ê±´ì„±(Robustness)**ê³¼ ì•ˆì „ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ì—¬, í™˜ê°(Hallucination)ì´ë‚˜ ê·¹ë‹¨ì  ì˜¤ì°¨ë¥¼ ë°©ì§€í•˜ëŠ” ì •ê·œí™”ëœ ëª¨ë¸ ì‚¬ìš©.

* **ì„ê³„ê°’ ìµœì í™” ì „ëµ (Threshold Optimization)**
ë³¸ ë°ëª¨ì—ì„œëŠ” ë°ì´í„°ì…‹ ê·œëª¨ë¥¼ ê³ ë ¤í•˜ì—¬ 0.5ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í–ˆìœ¼ë‚˜, ì‹¤ì œ ìµœì ì˜ ì„ê³„ê°’ì€ 6_0_calibrate_gate_threshold.pyë¥¼ í†µí•´ ìˆ˜í•™ì ìœ¼ë¡œ ë„ì¶œí•©ë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê²€ì¦ ë°ì´í„°(Validation Set)ì— ëŒ€í•œ Grid Searchë¥¼ ìˆ˜í–‰í•˜ì—¬, ì „ì²´ RMSE(ì˜¤ì°¨)ê°€ ìµœì†Œí™”ë˜ëŠ” ì§€ì ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ 6_1_inference_logp_real_world_prediction_ensemble.pyì˜ ì¶”ë¡  ê³¼ì •ì—ì„œ 'ì§ê´€'ì´ ì•„ë‹Œ 'ë°ì´í„°'ì— ê¸°ë°˜í•œ ëª¨ë¸ ì„ íƒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.



---

## 5. ì €ì¥ì†Œ êµ¬ì¡° (Repository Structure)

```text
Drug-Discovery-AI/
â”œâ”€â”€ 01_Property_Prediction/   # GNN (GCN, GAT) í•™ìŠµ ë° ì¶”ë¡ , í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ
â”œâ”€â”€ 02_3D_Structure/          # SchNet í•™ìŠµ ë° 3D êµ¬ì¡° ë¶„ì„
â”œâ”€â”€ 03_Generative_AI/         # ìƒì„± ëª¨ë¸ (VGAE, Diffusion)
â”œâ”€â”€ 04_Molecular_Interaction/ # ë‹¨ë°±ì§ˆ-ë¦¬ê°„ë“œ ê²°í•© ì‹œë®¬ë ˆì´ì…˜
â”œâ”€â”€ docs/                     # ì‹¤í—˜ ë³´ê³ ì„œ ë° ë¬¸ì„œ
â””â”€â”€ data/                     # ë°ì´í„°ì…‹ ì €ì¥ì†Œ

```

---

## 6. ì‚¬ìš©ë²• ë° ì¬í˜„ (Usage & Reproduction)

ë³¸ í”„ë¡œì íŠ¸ëŠ” `Python 3.8+` ë° `PyTorch Geometric` í™˜ê²½ì—ì„œ êµ¬ë™ë©ë‹ˆë‹¤.

### ì„¤ì¹˜ (Installation)

ìì„¸í•œ ì„¤ì • ë°©ë²•ì€ `install_guide.md`ë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤.

```bash
pip install -r requirements.txt

```

### 1. ë¬¼ì„± ì˜ˆì¸¡ (Property Prediction)

GAT ëª¨ë¸ í•™ìŠµ ë° í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œì„ ì´ìš©í•œ ì¶”ë¡ :

```bash
# ëª¨ë¸ í•™ìŠµ (Training)
python 01_Property_Prediction/train_gat.py

# í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ ì¶”ë¡  (Inference with Hybrid Strategy)
# *ë°ì´í„° ìœ ì‚¬ë„ì— ë”°ë¼ ìµœì ì˜ ëª¨ë¸ì„ ìë™ ì„ íƒí•©ë‹ˆë‹¤.
python 01_Property_Prediction/6_8_inference_final_complete.py

```

### 2. 3D ë¶„ì ë¶„ì„ (3D Molecular Analysis)

SchNetì„ ì´ìš©í•œ 3D êµ¬ì¡° ë° ì—ë„ˆì§€ ì˜ˆì¸¡ í•™ìŠµ:

```bash
python 02_3D_Structure/train_schnet.py

```

### 3. ìƒì„± ëª¨ë¸ (Generative Models)

Diffusion Modelì„ ì´ìš©í•œ 3D ë¶„ì êµ¬ì¡° ìƒì„±:

```bash
# í•™ìŠµ (Training)
python 03_Generative_AI/train_diffusion.py

# ìƒì„± ë° ì¶”ë¡  (Generation)
python 03_Generative_AI/inference_diffusion.py

```

### 4. ìƒí˜¸ì‘ìš© ì‹œë®¬ë ˆì´ì…˜ (Interaction Simulation)

íŠ¹ì • íƒ€ê²Ÿ(ì˜ˆ: Gleevec)ì— ëŒ€í•œ ê²°í•© ì‹œë®¬ë ˆì´ì…˜ ìˆ˜í–‰:

```bash
python 04_Molecular_Interaction/binding_gleevec.py

```

---

## 7. ë‹¨ë°±ì§ˆ ë””ìì¸ ë°ëª¨ (Protein Design Demo)

ë‹¨ë°±ì§ˆ ë””ìì¸ ì§ë¬´ì— ë§ì¶°, **ProteinMPNN(ì„œì—´ ë””ìì¸) â†’ ColabFold(êµ¬ì¡° ì˜ˆì¸¡) â†’ Scoring**ìœ¼ë¡œ ì´ì–´ì§€ëŠ” **Design-Predict-Validate** ë£¨í”„ ë°ëª¨ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.

* ìƒì„¸ ë‚´ìš©: `05_protein_design_demo/README.md`

## 8. ê²°ê³¼ë¬¼ (Outputs)

* `final_prediction.png`: ì‹¤ì œ LogP ê°’ê³¼ ëª¨ë¸ ì˜ˆì¸¡ê°’ ë¹„êµ ì‹œê°í™”
* `binding_pymol_final.png`: PyMOLì„ í™œìš©í•œ ë‹¨ë°±ì§ˆ-ë¦¬ê°„ë“œ ìƒí˜¸ì‘ìš© ì‹œê°í™”

## License

Distributed under the MIT License. See `LICENSE` for more information.